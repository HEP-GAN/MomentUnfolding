{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c95e6a-f568-4049-b588-81b1e10480f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from matplotlib import gridspec\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input, Layer, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "\n",
    "plt.rc('font', size=20)\n",
    "plt.rcParams[\"font.family\"] = \"serif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692ad1b9-a8ef-4e0f-967e-078b4c98cbb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_true = np.random.normal(0,1,100000)\n",
    "x_true_alt = np.random.normal(-0.5,1,100000)\n",
    "x_reco = np.random.normal(0,1,100000)\n",
    "x_reco_alt = np.random.normal(-0.5,1,100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e20eaf9-3a82-44d3-a964-53e913348124",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLayer(Layer):\n",
    "    def __init__(self, myc, **kwargs):\n",
    "        self.myinit = myc\n",
    "        super(MyLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Create a trainable weight variable for this layer.\n",
    "        self._lambda0 = self.add_weight(name='lambda0', \n",
    "                                    shape=(1,),\n",
    "                                    initializer=tf.keras.initializers.Constant(self.myinit), \n",
    "                                    trainable=True)\n",
    "        self._lambda1 = self.add_weight(name='lambda1', \n",
    "                                    shape=(1,),\n",
    "                                    initializer=tf.keras.initializers.Constant(self.myinit), \n",
    "                                    trainable=True)\n",
    "        super(MyLayer, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, x):\n",
    "        return tf.exp(self._lambda0 * x + self._lambda1 * x**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de288392-f26b-4dd8-977e-5ce005d06056",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def weighted_mlc(y_true, y_pred):\n",
    "    weights = tf.gather(y_true, [1], axis=1) # event weights\n",
    "    y_true = tf.gather(y_true, [0], axis=1) # actual y_true for loss\n",
    "    \n",
    "    # Clip the prediction value to prevent NaN's and Inf's\n",
    "    epsilon = K.epsilon()\n",
    "    y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "    t_loss = -weights * ((y_true) * K.log(y_pred) +\n",
    "                         (1 - y_true) * (1 - y_pred))\n",
    "    return K.mean(t_loss)\n",
    "\n",
    "def weighted_mlc_GAN(y_true, y_pred):\n",
    "    weights = tf.gather(y_pred, [1], axis=1) # event weights\n",
    "    y_pred = tf.gather(y_pred, [0], axis=1) # actual y_pred for loss\n",
    "    \n",
    "    weights_1 = K.sum(y_true*weights)\n",
    "    weights_0 = K.sum((1-y_true)*weights)\n",
    "    \n",
    "    # Clip the prediction value to prevent NaN's and Inf's\n",
    "    epsilon = K.epsilon()\n",
    "    y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "    t_loss = weights * ((1 - y_true) * (1 - y_pred)/weights_0)\n",
    "    return K.mean(t_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c08088-6152-435f-a693-fe51b48c7398",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xvals_1 = np.concatenate([x_true_alt,x_true])\n",
    "xvals_2 = np.concatenate([x_reco_alt,x_reco])\n",
    "yvals = np.concatenate([np.ones(len(x_true_alt)),np.zeros(len(x_true))])\n",
    "\n",
    "X_train_1, X_test_1, X_train_2, X_test_2, Y_train_1, Y_test_1 = train_test_split(xvals_1, xvals_2, yvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e3e0a1-49b9-4b86-b26e-de26520fcfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "myc = np.random.normal()\n",
    "\n",
    "mymodel_inputtest = Input(shape=(1,))\n",
    "mymodel_test = MyLayer(myc)(mymodel_inputtest)\n",
    "model_generator = Model(mymodel_inputtest, mymodel_test)\n",
    "\n",
    "inputs_disc = Input((1, ))\n",
    "hidden_layer_1_disc = Dense(50, activation='relu')(inputs_disc)\n",
    "hidden_layer_2_disc = Dense(50, activation='relu')(hidden_layer_1_disc)\n",
    "hidden_layer_3_disc = Dense(50, activation='relu')(hidden_layer_2_disc)\n",
    "outputs_disc = Dense(1, activation='sigmoid')(hidden_layer_3_disc)\n",
    "model_discrimantor = Model(inputs=inputs_disc, outputs=outputs_disc)\n",
    "\n",
    "model_discrimantor.compile(loss=weighted_mlc, optimizer='adam')\n",
    "\n",
    "model_discrimantor.trainable = False\n",
    "mymodel_gan = Input(shape=(1,))\n",
    "gan_model = Model(inputs=mymodel_gan,outputs=concatenate([model_discrimantor(mymodel_gan),model_generator(mymodel_gan)]))\n",
    "\n",
    "gan_model.compile(loss=weighted_mlc_GAN, optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e28899-9b00-4905-80f0-970d55e42136",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_epochs = 500\n",
    "n_batch = 128*10\n",
    "n_batches = len(X_train_1) // n_batch\n",
    "lambdas = []\n",
    "\n",
    "\n",
    "for i in range(n_epochs):\n",
    "    for j in range(n_batches):\n",
    "        X_batch_1 = X_train_1[j*n_batch:(j+1)*n_batch]\n",
    "        X_batch_2 = X_train_1[j*n_batch:(j+1)*n_batch]\n",
    "        Y_batch = Y_train_1[j*n_batch:(j+1)*n_batch]\n",
    "        W_batch = model_generator(X_batch_1)\n",
    "        W_batch = np.array(W_batch).flatten()\n",
    "        W_batch[Y_batch==1] = 1        \n",
    "        Y_batch_2 = np.stack((Y_batch, W_batch), axis=1)\n",
    "        \n",
    "        model_discrimantor.train_on_batch(X_batch_2, Y_batch_2)        \n",
    "        gan_model.train_on_batch(X_batch_1[Y_batch==0],np.zeros(len(X_batch_2[Y_batch==0])))\n",
    "    lambdasum = np.log(model_generator.predict([1.], verbose = 0))\n",
    "    lambdasum2 = np.log(model_generator.predict([2.], verbose = 0))\n",
    "    mylambda1 = (lambdasum2-2*lambdasum)/2\n",
    "    mylambda0 = lambdasum - mylambda1\n",
    "    if i%20 == 0:\n",
    "        print(\"on epoch=\",i,mylambda0,mylambda1)\n",
    "    lambdas += [[mylambda0, mylambda1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75eea455-4924-4e29-8690-5234b5c720a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "truth = X_test_1[Y_test_1==0]\n",
    "gen = X_test_1[Y_test_1==1]\n",
    "data = X_test_2[Y_test_1==0]\n",
    "sim = X_test_2[Y_test_1==1]\n",
    "\n",
    "total_err = []\n",
    "\n",
    "for lambda0, lambda1 in lambdas:\n",
    "    weights = (np.exp(lambda1*gen**2+lambda0*gen)*len(data)/np.sum(np.exp(lambda1*gen**2+lambda0*gen)))[0]\n",
    "    mean_err = (np.average(gen, weights = weights) - truth.mean())\n",
    "    var_err = np.average(gen**2, weights = weights) - np.mean(truth**2)\n",
    "    total_err += [(mean_err)**2 + var_err]\n",
    "    \n",
    "lambda0, lambda1 = lambdas[np.argmin(total_err)]\n",
    "weights = (np.exp(lambda1*gen**2+lambda0*gen)*len(data)/np.sum(np.exp(lambda1*gen**2+lambda0*gen)))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e38cf89-017e-45ad-b62a-f1df0c816087",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "_,_,_=plt.hist(truth, bins=np.linspace(-4,4,20), alpha=0.5, label=\"Truth\", density=True)\n",
    "_,_,_=plt.hist(gen, bins=np.linspace(-4,4,20), alpha=0.5, label=\"Generation\", density=True)\n",
    "_,_,_=plt.hist(gen, bins=np.linspace(-4,4,20), weights=weights, histtype=\"step\", color='black', ls=\":\", lw=4, label=\"Moment Unfolding\", density=True)\n",
    "\n",
    "plt.legend(fontsize=24)\n",
    "plt.xlabel(\"z (particle level)\", fontsize=24)\n",
    "plt.ylabel(\"Counts\", fontsize=24)\n",
    "plt.title(\"Gaussian Data: Particle Level Histograms\", fontsize=24)\n",
    "\n",
    "plt.savefig(\"figures/gaussexample.pdf\", bbox_inches='tight', transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a85384-d6c2-4e6d-91ce-e9fa658747f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-2.9.0",
   "language": "python",
   "name": "tensorflow-2.9.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
