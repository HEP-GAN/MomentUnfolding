{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from matplotlib import gridspec\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input, Layer, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "\n",
    "plt.rc('font', size=20)\n",
    "plt.rcParams[\"font.family\"] = \"serif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "normalize = True\n",
    "data_size = 10**6\n",
    "n_moments = 2\n",
    "mylambda = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "moment = 2\n",
    "obs = 'q'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#load and normalize the data\n",
    "data = np.load('npfiles/rawdata.npz')\n",
    "substructure_variables = ['pT', 'w', 'q', 'm', 'r', 'tau1s', 'tau2s']\n",
    "data_streams = ['_true', '_true_alt', '_reco', '_reco_alt']\n",
    "n_variables = len(substructure_variables)\n",
    "\n",
    "\n",
    "normalize = True\n",
    "    \n",
    "for stream in data_streams:\n",
    "    globals()['pT'+stream] = data['pT'+stream][:150000]\n",
    "    globals()['x'+stream] = data[obs+stream][:150000]\n",
    "    \n",
    "xm, xs = (x_true_alt.mean(), x_true_alt.std()) if normalize else (0, 1)\n",
    "pm, ps = (pT_true_alt.mean(), pT_true_alt.std()) if normalize else (0, 1)\n",
    "\n",
    "for stream in data_streams:\n",
    "    globals()['x'+stream] = (globals()['x'+stream] - xm)/xs\n",
    "    globals()['pT'+stream] = (globals()['pT'+stream] - pm)/ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MyLayer(Layer):\n",
    "\n",
    "    def __init__(self, myc, **kwargs):\n",
    "        self.myinit = myc\n",
    "        super(MyLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Create a trainable weight variable for this layer.\n",
    "        self.m0 = self.add_weight(name='m0', \n",
    "                                    shape=(1,),\n",
    "                                    initializer=tf.keras.initializers.Constant(self.myinit[0]), \n",
    "                                    trainable=True)\n",
    "        self.m1 = self.add_weight(name='m1', \n",
    "                                    shape=(1,),\n",
    "                                    initializer=tf.keras.initializers.Constant(self.myinit[1]), \n",
    "                                    trainable=True)\n",
    "        self.v0 = self.add_weight(name='v0', \n",
    "                                    shape=(1,),\n",
    "                                    initializer=tf.keras.initializers.Constant(self.myinit[2]), \n",
    "                                    trainable=True)\n",
    "        self.v1 = self.add_weight(name='v1', \n",
    "                                    shape=(1,),\n",
    "                                    initializer=tf.keras.initializers.Constant(self.myinit[3]), \n",
    "                                    trainable=True)\n",
    "        super(MyLayer, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, x):\n",
    "        y = tf.exp((self.m0 + self.m1*x[:, 0]) * x[:,1] + (self.v0 + self.v1*x[:,0]) * x[:,1]**2)\n",
    "        return tf.reshape(y, (len(x), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def weighted_mlc(y_true, y_pred):\n",
    "    weights = tf.gather(y_true, [1], axis=1) # event weights\n",
    "    y_true = tf.gather(y_true, [0], axis=1) # actual y_true for loss\n",
    "    \n",
    "    weights_1 = K.sum(y_true*weights)\n",
    "    weights_0 = K.sum((1-y_true)*weights)\n",
    "    \n",
    "    # Clip the prediction value to prevent NaN's and Inf's\n",
    "    epsilon = K.epsilon()\n",
    "    y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "    t_loss = -weights * ((y_true) * K.log(y_pred)/weights_1 +\n",
    "                         (1 - y_true) * (1 - y_pred)/weights_0)\n",
    "    return K.mean(t_loss)\n",
    "\n",
    "def weighted_mlc_GAN(y_true, y_pred):\n",
    "    weights = tf.gather(y_pred, [1], axis=1) # event weights\n",
    "    y_pred = tf.gather(y_pred, [0], axis=1) # actual y_pred for loss\n",
    "    \n",
    "    weights_1 = K.sum(y_true*weights)\n",
    "    weights_0 = K.sum((1-y_true)*weights)\n",
    "    \n",
    "    \n",
    "    # Clip the prediction value to prevent NaN's and Inf's\n",
    "    epsilon = K.epsilon()\n",
    "    y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "    t_loss = weights * ((1 - y_true) * (1 - y_pred)/weights_0)\n",
    "    return K.mean(t_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "myc = np.random.normal(0, 0.01, 4)\n",
    "mymodel_inputtest = Input(shape=(2,))\n",
    "mymodel_test = MyLayer(myc)(mymodel_inputtest)\n",
    "model_generator = Model(mymodel_inputtest, mymodel_test)\n",
    "\n",
    "inputs_disc = Input((2, ))\n",
    "hidden_layer_1_disc = Dense(50, activation='relu')(inputs_disc)\n",
    "hidden_layer_2_disc = Dense(50, activation='relu')(hidden_layer_1_disc)\n",
    "hidden_layer_3_disc = Dense(50, activation='relu')(hidden_layer_2_disc)\n",
    "outputs_disc = Dense(1, activation='sigmoid')(hidden_layer_3_disc)\n",
    "model_discrimintor = Model(inputs=inputs_disc, outputs=outputs_disc)\n",
    "\n",
    "model_discrimintor.compile(loss=weighted_mlc, optimizer=tf.keras.optimizers.Adam())\n",
    "    \n",
    "model_discrimintor.trainable = False\n",
    "mymodel_gan = Input(shape=(2,))\n",
    "gan_model = Model(inputs=mymodel_gan,outputs=concatenate([model_discrimintor(mymodel_gan),model_generator(mymodel_gan)]))\n",
    "\n",
    "gan_model.compile(loss=weighted_mlc_GAN, optimizer=tf.keras.optimizers.Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xvals_particle = np.transpose([np.concatenate([x_true_alt,x_true]), np.concatenate([pT_true_alt,pT_true])])\n",
    "xvals_detector = np.transpose([np.concatenate([x_reco_alt,x_reco]), np.concatenate([pT_reco_alt,pT_reco])])                        \n",
    "yvals = np.transpose(np.concatenate([np.ones(len(x_true_alt)),np.zeros(len(x_true))]))\n",
    "\n",
    "X_train_particle, X_test_particle, X_train_detector, X_test_detector, Y_train, Y_test = train_test_split(xvals_particle, \n",
    "                                                                                                        xvals_detector,\n",
    "                                                                                                        yvals)\n",
    "\n",
    "betas = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_epochs = 50\n",
    "n_batch = 128*100\n",
    "n_batches = len(X_train_particle) // n_batch\n",
    "\n",
    "for i in range(n_epochs):\n",
    "    #print(\"  \",np.sum(model_generator.predict(X_train_1,batch_size=1000)))\n",
    "    for j in range(n_batches):\n",
    "        X_batch_particle = X_train_particle[j*n_batch:(j+1)*n_batch]\n",
    "        X_batch_detector = X_train_detector[j*n_batch:(j+1)*n_batch]\n",
    "        Y_batch = Y_train[j*n_batch:(j+1)*n_batch]\n",
    "        W_batch = model_generator(X_batch_particle)\n",
    "        W_batch = np.array(W_batch).flatten()\n",
    "        \n",
    "        W_batch[Y_batch==1] = 1        \n",
    "        Y_batch_2 = np.stack((Y_batch, W_batch), axis=1)\n",
    "        \n",
    "        model_discrimintor.train_on_batch(X_batch_detector, Y_batch_2)        \n",
    "        gan_model.train_on_batch(X_batch_particle[Y_batch==0],Y_batch[Y_batch==0])\n",
    "    betas += [np.array(model_generator.layers[-1].get_weights())]\n",
    "    if i%20 == 0:\n",
    "        print(\"on epoch=\", i, np.mean(betas))\n",
    "    if np.isnan(np.mean(betas)):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "truth = X_test_particle[Y_test==0]\n",
    "gen = X_test_particle[Y_test==1]\n",
    "data = X_test_detector[Y_test==0]\n",
    "sim = X_test_detector[Y_test==1]\n",
    "\n",
    "total_err = []\n",
    "\n",
    "for mylambda in betas:\n",
    "    arr = np.exp(\n",
    "        (mylambda[0] + mylambda[1] * gen[:, 1]) * gen[:, 0]\n",
    "        + (mylambda[2] + mylambda[3]*gen[:, 1]) * gen[:, 0]**2\n",
    "    )\n",
    "    weights_moment_uf = (arr*len(data)/np.sum(arr))\n",
    "\n",
    "    mean_err = (np.average(gen[:, 0], weights = weights_moment_uf) - truth[:, 0].mean())\n",
    "    var_err = np.average(gen[:, 0]**2, weights = weights_moment_uf) - np.mean(truth[:, 0]**2)\n",
    "    total_err += [(mean_err)**2 + var_err]\n",
    "    \n",
    "mylambda = betas[np.argmin(total_err)]\n",
    "arr = np.exp(\n",
    "    (mylambda[0] + mylambda[1] * gen[:, 1]) * gen[:, 0]\n",
    "    + (mylambda[2] + mylambda[3]*gen[:, 1]) * gen[:, 0]**2\n",
    "    )\n",
    "weights_moment_uf = arr*len(data)/np.sum(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "truth = X_test_particle[Y_test==0][:, 0] * xs + xm\n",
    "gen = X_test_particle[Y_test==1][:, 0]* xs + xm\n",
    "data = X_test_detector[Y_test==0][:, 0]* xs + xm\n",
    "sim = X_test_detector[Y_test==1][:, 0]* xs + xm\n",
    "\n",
    "\n",
    "bins = np.linspace(truth.min(), truth.max(), 30)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "_,_,_=plt.hist(truth, bins=bins, alpha=0.5, label=\"Truth\", density=True)\n",
    "_,_,_=plt.hist(gen, bins=bins, alpha=0.5, label=\"Generation\", density=True)\n",
    "_,_,_=plt.hist(gen, bins=bins, weights=weights_moment_uf, histtype=\"step\", color='black', ls=\":\", lw=4, label=\"Moment Unfolding\", density=True)\n",
    "\n",
    "plt.legend(fontsize=24)\n",
    "plt.xlabel(\"z (particle level)\", fontsize=24)\n",
    "plt.ylabel(\"Counts\", fontsize=24)\n",
    "plt.title(f\"Jet {obs} Data: $p_T$ Conditioned Inclusive Histograms\", fontsize=24)\n",
    "\n",
    "plt.savefig(f\"figures/{obs}pjetexample.pdf\", bbox_inches='tight', transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "binvals = [pT_true.min()]\n",
    "i = 0\n",
    "while binvals[-1] < pT_true.max() and i < len(binvals):\n",
    "    for binhigh in np.linspace(binvals[i] + 0.01, pT_true.max(), 100):\n",
    "        in_bin = (pT_true > binvals[i]) & (pT_true < binhigh)\n",
    "        in_reco_bin = (pT_reco > binvals[i]) & (pT_reco < binhigh)\n",
    "        if np.sum(in_bin) > 0:\n",
    "            purity = np.sum(in_bin & in_reco_bin) / np.sum(in_bin)\n",
    "            if purity > np.sqrt(0.5):\n",
    "                print(f\"{binhigh = }, {purity = }\")\n",
    "                i += 1\n",
    "                binvals.append(binhigh)\n",
    "                break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "print(f\"{len(binvals) = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_bins =len(binvals) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pTbin_truth = np.clip(np.digitize(pT_true,binvals),1,n_bins)-1\n",
    "pTbin_reco = np.clip(np.digitize(pT_reco,binvals),1,n_bins)-1\n",
    "pTbin_truth_alt = np.clip(np.digitize(pT_true_alt,binvals),1, n_bins)-1\n",
    "pTbin_reco_alt = np.clip(np.digitize(pT_reco_alt,binvals),1, n_bins)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "binvals = np.array(binvals)\n",
    "binmid = (binvals[:-1] + binvals[1:])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pTbin_gen_test = (np.clip(np.digitize(X_test_particle[:,1],binvals),1,n_bins)-1)[Y_test==0]\n",
    "pTbin_truth_test = (np.clip(np.digitize(X_test_particle[:,1],binvals),1,n_bins)-1)[Y_test==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "means_moment_unfolding = np.empty(n_bins)\n",
    "truth_p = np.empty(n_bins)\n",
    "gen_p = np.empty(n_bins)\n",
    "\n",
    "truth_std = np.array([np.std(truth**moment) for i in range(n_bins)])\n",
    "n_array = np.array([len(truth[pTbin_truth == i]) for i in range(n_bins)])\n",
    "\n",
    "for i in range(n_bins):\n",
    "    means_moment_unfolding[i] = np.average((gen[pTbin_gen_test==i])**moment, weights = weights_moment_uf)\n",
    "    gen_p[i] = np.average((gen[pTbin_gen_test==i])**moment)\n",
    "    truth_p[i] = np.average((truth[pTbin_truth_test==i])**moment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "drop = 2\n",
    "markersize = 10\n",
    "def plot_data(ax, y, label, marker, color):\n",
    "    x = binmid[:-drop]*ps + pm\n",
    "    y = y[:-drop]*xs + xm\n",
    "    \n",
    "    if label == 'Truth':\n",
    "        yerr = (truth_std/np.sqrt(n_array))[:-drop]\n",
    "        ax.errorbar(x, y, yerr=yerr, linestyle='--', color=color, alpha=1, capsize=3, \n",
    "                       label=label, marker=marker, mec=color, mfc='none', ms=markersize)\n",
    "        ax.plot(x, y, linestyle='--', \n",
    "                   color=color, alpha = 1, marker=marker,\n",
    "                  mec=color, mfc='none', ms=markersize)\n",
    "    else:    \n",
    "        ax.plot(x, y, linestyle='--', \n",
    "                   color=color, alpha = 1, label=label, marker=marker,\n",
    "                  mec=color, mfc='none', ms=markersize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    (means_moment_unfolding, 'Moment Unfolding', 'o', 'black'),\n",
    "    (truth_p, 'Truth', 'v', 'blue'),\n",
    "    (gen_p, 'Generation', '^', 'orange')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "\n",
    "# Plot settings for ax0\n",
    "ax.yaxis.set_ticks_position('both')\n",
    "ax.xaxis.set_ticks_position('both')\n",
    "ax.tick_params(direction=\"in\", which=\"both\")\n",
    "ax.minorticks_on()\n",
    "#ax[0].set_ylim(0.0, 0.2)\n",
    "#ax.set_xlim(100.0, 700)\n",
    "\n",
    "for sets, label, marker, color in datasets:\n",
    "    plot_data(ax, sets, label, marker, color)\n",
    "\n",
    "ylabel = r'$\\langle {} \\rangle$'.format(obs.upper()) if moment == 1 else r'$\\langle {}^{} \\rangle$'.format(obs.upper(), moment)\n",
    "if obs == 'm':\n",
    "    unit = ' [GeV]' if moment == 1 else ' [GeV$^{}$]'.format(moment)\n",
    "    ylabel += unit\n",
    "ax.set_ylabel(ylabel, fontsize=28)\n",
    "\n",
    "ax.legend(frameon=True, fontsize=28)\n",
    "ax.set_xlabel(\"Jet $p_{T}$ [GeV]\", fontsize=28)\n",
    "\n",
    "\n",
    "\n",
    "fig.savefig('figures/p{}jet{}.pdf'.format(obs, moment), bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-2.9.0",
   "language": "python",
   "name": "tensorflow-2.9.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
